name : New_Pipeline

on:
  workflow_dispatch:
     inputs:
       run_all:
         description: 'Run all jobs'
         required: false
         default: 'true'
       run_data_processing:
         description: 'Run data processing job'
         required: false
         default: 'false'
       run_model_training:
         description: 'Run model training job'
         required: false
         default: 'false'
       run_build_and_push:
         description: 'Run build and push job'
         required: false
         default: 'false'

     releases:
        types: [created]
        branches: [main]
        tags: ['v*.*.*']

jobs:
  data_processing:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11.13'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Data Processing tests
      run: |
        python src/data/run_processing.py \
          --input data/raw/house_data.csv \
          --output data/processed/cleaned_house_data.csv
    
    - name: Feature Engineering
      run: |  
        python src/features/engineer.py \
          --input data/processed/cleaned_house_data.csv \
          --output data/processed/feature_house_data.csv \
          --preprocessor models/trained/preprocessor.pkl

    - name: Upload processed data
      uses: actions/upload-artifact@v4
      with:
        name: processed-data
        path: data/processed/feature_house_data.csv
    - name: Upload preprocessor
      uses: actions/upload-artifact@v4
      with:
        name: preprocessor
        path: models/trained/preprocessor.pkl

  model_training:
    runs-on: ubuntu-latest
    needs: data_processing
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11.13'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    

    - name: Download processed data
      uses: actions/download-artifact@v4
      with:
        name: processed-data
        path: data/processed/feature_house_data.csv

    - name: Set up MLflow
      run: |
        docker pull ghcr.io/mlflow/mlflow:latest
        docker run -d -p 5000:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest \
       
    - name: Wait for MLflow to be ready
      run: |
        for i in {1..10}; do
          if curl -s http://localhost:5000/health | grep -q '"status":"healthy"'; then
            echo "MLflow is up and running"
            break
          fi
          echo "Waiting for MLflow to start..."
          sleep 5
        done
    - name: Train the model
        run: |
          mkdir -p models
          python src/models/train_model.py \
          --config configs/model_config.yaml \
          --data data/processed/featured_house_data.csv \
          --models-dir models \
          --mlflow-tracking-uri http://localhost:5555 
    - name: Cleanup MLflow container
      run: |
        docker stop mlflow-server
        docker rm mlflow-server

    

  build_and_publish:
      runs-on: ubuntu-latest
      needs: model_training
      steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download trained model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/trained/house_price_model.pkl
      - name: Download preprocessor
        uses: actions/download-artifact@v4
        with:
          name: preprocessor 
          path: models/trained/preprocessor.pkl
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and Test Docker image
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH} -f Dockerfile .
          
          docker run -d -p 8000:8000 --name test-api docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH}
          for i in {1..10}; do
            if curl -s http://localhost:8000/health | grep -q '"status":"ok"'; then
              echo "API is up and running"
              break
            fi
            echo "Waiting for API to start..."
            sleep 2
          done
          docker logs test-api

      - name: Clean up Test Container
        run: |
          docker stop test-api || true
          docker rm test-api || true

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          registry: docker.io
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Push Docker image to Docker Hub
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker tag docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH} docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:$COMMIT_HASH
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
      





